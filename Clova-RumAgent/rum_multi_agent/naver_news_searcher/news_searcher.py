"""
ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ëª¨ë“ˆ
"""
from dotenv import load_dotenv
load_dotenv()

import requests
import urllib.parse
import re
from datetime import datetime
from typing import Dict, List
from dateutil import parser
import os
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
import json

NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
NAVER_NEWS_API_URL = "https://openapi.naver.com/v1/search/news.json"
DEFAULT_DISPLAY = 10
DEFAULT_SORT = "sim"  # sim: ìœ ì‚¬ë„ìˆœ, date: ë‚ ì§œìˆœ

# ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸ ìƒì„± í…œí”Œë¦¿
search_prompt_template = ChatPromptTemplate.from_template("""
ë„ˆëŠ” ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°ì•¼.

ì‚¬ìš©ìê°€ í•œ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ, ì£¼ì œì— ë§ëŠ” ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•´.
ì´ í‚¤ì›Œë“œë“¤ì€ ì‹¤ì œ ë‰´ìŠ¤Â·ë¦¬í¬íŠ¸Â·ë°ì´í„° ê²€ìƒ‰ì— ì“°ì¼ ìˆ˜ ìˆì–´ì•¼ í•´.

ê·œì¹™:
1. ì§ˆë¬¸ì—ì„œ í•µì‹¬ ê°œì²´(ì˜ˆ: ê¸°ì—…, ì¸ë¬¼, ì‚¬ê±´, ì£¼ì œ)ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•  ê²ƒ.
2. ì§ˆë¬¸ì˜ ì˜ë„ì— ë§ëŠ” ë³´ì¡° í‚¤ì›Œë“œ(ì˜ˆ: ì˜í–¥, ì´ìœ , ì‹¤ì , ìµœê·¼, ê·œëª¨, ê¸ˆì•¡ ë“±)ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŒ.
3. ì£¼ì œì—ì„œ ë²—ì–´ë‚˜ì§€ ì•Šê²Œ, ê´€ë ¨ì„± ë†’ì€ 3~5ê°œì˜ ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ë¼.
4. ê²°ê³¼ëŠ” JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ë¼.

ğŸ“˜ ì°¸ê³  íŒ¨í„´:
- ì¬ë¬´/ì‹¤ì í˜• ì§ˆë¬¸ â†’ ["ê¸°ì—…ëª… ì‹¤ì ", "ê¸°ì—…ëª… ë§¤ì¶œ", "ê¸°ì—…ëª… ì˜ì—…ì´ìµ ìµœê·¼"]
- ì¸ë¬¼ ì˜í–¥í˜• ì§ˆë¬¸ â†’ ["ì¸ë¬¼ëª… ê¸°ì—…ëª… ì˜í–¥", "ê¸°ì—…ëª… ì‹¤ì  ë³€í™” ì´ìœ ", "ì¸ë¬¼ëª… ê¸°ì—…ëª… ìµœê·¼ ë‰´ìŠ¤"]
- ì‚¬ê±´í˜• ì§ˆë¬¸ â†’ ["ì‚¬ê±´ëª… ë°°ê²½", "ì‚¬ê±´ëª… ì˜í–¥", "ì‚¬ê±´ëª… ê´€ë ¨ ê¸°ì—…"]
- ê¸ˆì•¡/ê·œëª¨í˜• ì§ˆë¬¸ â†’ ["ê¸°ì—…ëª… ìì‚¬ì£¼ ì†Œê° ê·œëª¨", "ê¸°ì—…ëª… ìì‚¬ì£¼ ì†Œê° ëª‡ ì¡°ì›", "ê¸°ì—…ëª… ìì‚¬ì£¼ ì†Œê° ê¸ˆì•¡ ìµœê·¼"]

ì¶œë ¥ ì˜ˆì‹œ:
ì…ë ¥: "ë°©ì‹œí˜ ë•Œë¬¸ì— í•˜ì´ë¸Œ ë§¤ì¶œì´ ì¤„ì—ˆì–´?"
ì¶œë ¥:
{{
  "query": "ë°©ì‹œí˜ ë•Œë¬¸ì— í•˜ì´ë¸Œ ë§¤ì¶œì´ ì¤„ì—ˆì–´?",
  "search_prompts": [
    "ë°©ì‹œí˜ í•˜ì´ë¸Œ ë§¤ì¶œ ì˜í–¥",
    "í•˜ì´ë¸Œ ë§¤ì¶œ ê°ì†Œ ì´ìœ ",
    "ë°©ì‹œí˜ í•˜ì´ë¸Œ ìµœê·¼ ë‰´ìŠ¤"
  ]
}}

ì´ì œ ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´.
ì§ˆë¬¸: {user_query}
""")

class NewsSearcher:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ í´ë˜ìŠ¤"""

    def __init__(self, client_id: str = None, client_secret: str = None):
        """ì´ˆê¸°í™”"""
        self.client_id = client_id or NAVER_CLIENT_ID
        self.client_secret = client_secret or NAVER_CLIENT_SECRET

        if not self.client_id or not self.client_secret:
            raise ValueError("ë„¤ì´ë²„ API í´ë¼ì´ì–¸íŠ¸ IDì™€ ì‹œí¬ë¦¿ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")

        # Claude ëª¨ë¸ ì´ˆê¸°í™”
        self.llm = ChatAnthropic(
            model="claude-3-5-haiku-latest",
            temperature=0
        )

    def search_news(
        self, 
        query: str, 
        display: int = DEFAULT_DISPLAY, 
        start: int = 1, 
        sort: str = DEFAULT_SORT
    ) -> Dict:
        """ë‰´ìŠ¤ ê²€ìƒ‰"""
        encoded_query = urllib.parse.quote(query)
        url = f"{NAVER_NEWS_API_URL}?query={encoded_query}&display={display}&start={start}&sort={sort}"
        
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret,
            "User-Agent": "StockNewsSearcher/1.0"
        }

        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            raise Exception(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def generate_search_prompts(self, user_query: str) -> List[str]:
        """ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±"""
        chain = search_prompt_template | self.llm

        try:
            response = chain.invoke({"user_query": user_query})
            response_text = response.content

            # JSON íŒŒì‹±
            json_data = json.loads(response_text)
            search_prompts = json_data.get("search_prompts", [])

            print(f"ìƒì„±ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ: {search_prompts}")
            return search_prompts

        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì‘ë‹µ ë‚´ìš©: {response_text}")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì§ˆë¬¸ ë°˜í™˜
            return [user_query]
        except Exception as e:
            print(f"ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return [user_query]

    def search_query(self, query: str, display: int = DEFAULT_DISPLAY, sort: str = DEFAULT_SORT) -> Dict:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¡œ í‚¤ì›Œë“œ ìƒì„± í›„ ë‰´ìŠ¤ ê²€ìƒ‰"""
        # ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
        search_keywords = self.generate_search_prompts(query)

        # ëª¨ë“  í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘
        all_results = {"items": []}

        for keyword in search_keywords:
            print(f"í‚¤ì›Œë“œ '{keyword}'ë¡œ ê²€ìƒ‰ ì¤‘...")
            result = self.search_news(keyword, display//len(search_keywords) or 1, sort=sort)

            if 'items' in result:
                all_results['items'].extend(result['items'])

        # ì¤‘ë³µ ì œê±° (ë§í¬ ê¸°ì¤€)
        seen_links = set()
        unique_items = []
        for item in all_results['items']:
            link = item.get('link', '')
            if link and link not in seen_links:
                seen_links.add(link)
                unique_items.append(item)

        all_results['items'] = unique_items[:display]
        print(f"ìµœì¢… ê²€ìƒ‰ëœ ë‰´ìŠ¤ ê°œìˆ˜: {len(all_results['items'])}ê°œ")

        # í¬ë§·íŒ…
        if 'items' in all_results:
            all_results['items'] = [self.format_news_item(item) for item in all_results['items']]

        NewsSearcher.save_results_to_file(all_results, query, search_keywords)
        return all_results

    @staticmethod
    def clean_html_tags(text: str) -> str:
        """HTML íƒœê·¸ ì œê±°"""
        if not text:
            return ""
        cleaned = re.sub(r'<[^>]+>', '', text)
        return cleaned.strip()

    @staticmethod
    def format_news_item(item: Dict) -> Dict:
        print(f"Itemì˜ í‚¤ë“¤: {list(item.keys())}")
        """ë‰´ìŠ¤ ì•„ì´í…œ í¬ë§·íŒ…"""
        return {
            'title': NewsSearcher.clean_html_tags(item.get('title', '')),
            'description': NewsSearcher.clean_html_tags(item.get('description', '')),
            'link': item.get('link', ''),
            'original_link': item.get('originallink', ''),
            'pub_date': item.get('pubDate', ''),
            'formatted_date': NewsSearcher.format_date(item.get('pubDate', ''))
        }

    @staticmethod
    def format_date(date_str: str) -> str:
        """ë‚ ì§œ í¬ë§·íŒ…"""
        if not date_str:
            return ""
        try:
            dt = parser.parse(date_str)
            return dt.strftime("%Y-%m-%d %H:%M")
        except:
            return date_str
    
    @staticmethod
    def save_results_to_file(results: Dict, original_query: str = None, search_keywords: List[str] = None) -> None:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        now = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"/home/sese/Clova-RumAgent/rum_multi_agent/naver_news_searcher/log/news_search_results_{now}.txt"
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                # ê²€ìƒ‰ ì •ë³´ í—¤ë” ì¶”ê°€
                f.write("=" * 60 + "\n")
                f.write(f"ê²€ìƒ‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                if original_query:
                    f.write(f"ì›ë³¸ ì§ˆë¬¸: {original_query}\n")
                if search_keywords:
                    f.write(f"ìƒì„±ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(search_keywords)}\n")
                f.write(f"ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜: {len(results.get('items', []))}ê°œ\n")
                f.write("=" * 60 + "\n\n")

                for item in results.get('items', []):
                    f.write(f"Title: {item['title']}\n")
                    f.write(f"Link: {item['link']}\n")
                    f.write(f"Date: {item['formatted_date']}\n")
                    f.write(f"Description: {item['description']}\n")
                    f.write("-" * 40 + "\n")
            print(f"ê²€ìƒ‰ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    searcher = NewsSearcher()
    query = "ë°©ì‹œí˜ ë•Œë¬¸ì— í•˜ì´ë¸Œ ë§¤ì¶œì´ ì¤„ì—ˆì–´?"

    print("=== í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")
    news_data = searcher.search_query(query, display=10, sort="date")
    for item in news_data.get('items', []):
        print(f"Title: {item['title']}")
        print(f"Link: {item['link']}")
        print(f"Date: {item['formatted_date']}")
        print(f"Description: {item['description']}")
        print("-" * 40)